{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fda04c5",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/billydavila/CSC448/blob/main/Judging%20Flowers/Judging_flowers.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1e3ea",
   "metadata": {},
   "source": [
    "# Judging Flowers (Iris Dataset)\n",
    "\n",
    "![irisPic](https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/irisPic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698426c0",
   "metadata": {},
   "source": [
    "# Imports and pip installations (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3847b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\billd\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.9)\n"
     ]
    }
   ],
   "source": [
    "# pip installations\n",
    "!pip install tabulate\n",
    "\n",
    "\n",
    "# libraries\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn import linear_model, model_selection, preprocessing, pipeline, metrics, svm, neural_network, neighbors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7436db8",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90cbf67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "\n",
      "Feature Names:  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Target:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "\n",
      "Target Names:  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "\n",
    "# load the data\n",
    "iris = load_iris() \n",
    "\n",
    "# Display to console\n",
    "print( \"Data: \") \n",
    "print( iris.data[:10])\n",
    "print( \"\\nFeature Names:\", end = \"  \" )\n",
    "print( iris.feature_names )\n",
    "print( \"\\nTarget: \", end = \" \")\n",
    "print(iris.target)\n",
    "print(\"\\nTarget Names: \", end = \" \")\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7ec066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                 5.1               3.5                1.4               0.2   \n",
       "1                 4.9               3.0                1.4               0.2   \n",
       "2                 4.7               3.2                1.3               0.2   \n",
       "3                 4.6               3.1                1.5               0.2   \n",
       "4                 5.0               3.6                1.4               0.2   \n",
       "5                 5.4               3.9                1.7               0.4   \n",
       "6                 4.6               3.4                1.4               0.3   \n",
       "7                 5.0               3.4                1.5               0.2   \n",
       "8                 4.4               2.9                1.4               0.2   \n",
       "9                 4.9               3.1                1.5               0.1   \n",
       "10                5.4               3.7                1.5               0.2   \n",
       "11                4.8               3.4                1.6               0.2   \n",
       "12                4.8               3.0                1.4               0.1   \n",
       "13                4.3               3.0                1.1               0.1   \n",
       "14                5.8               4.0                1.2               0.2   \n",
       "\n",
       "   species  target  \n",
       "0   setosa       0  \n",
       "1   setosa       0  \n",
       "2   setosa       0  \n",
       "3   setosa       0  \n",
       "4   setosa       0  \n",
       "5   setosa       0  \n",
       "6   setosa       0  \n",
       "7   setosa       0  \n",
       "8   setosa       0  \n",
       "9   setosa       0  \n",
       "10  setosa       0  \n",
       "11  setosa       0  \n",
       "12  setosa       0  \n",
       "13  setosa       0  \n",
       "14  setosa       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put everything nicely in a single DataFrame\n",
    "featureDataFrame = pd.DataFrame( data = iris.data, columns = iris.feature_names, )\n",
    "listTarget_names = [f'{iris.target_names[0]}']*50 + [f'{iris.target_names[1]}']*50 + [f'{iris.target_names[2]}']*50\n",
    "speciesDataFrame = pd.DataFrame( data = listTarget_names, columns = ['species'])\n",
    "targetDataFrame = pd.DataFrame( data = iris.target, columns = ['target'] )\n",
    "irisDataFrame = pd.concat( [featureDataFrame, speciesDataFrame,targetDataFrame ], axis = 1)\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "irisDataFrame.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f15b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   species            150 non-null    object \n",
      " 5   target             150 non-null    int32  \n",
      "dtypes: float64(4), int32(1), object(1)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "irisDataFrame.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07251712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDataFrame.describe() # Display the Descriptive statistics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f1feb",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?\n",
    "![irisDataPictures](https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/iris-datasetPic.png)\n",
    "\n",
    "\n",
    "* The iris data set is widely used as a beginner's dataset for machine learning purposes. The dataset is included in R base and Python in the machine learning package Scikit-learn, so that users can access it without having to find a source for it. Several versions of the dataset have been published (But we will be using the one provided by `sklearn.datasets`).\n",
    "* The dataset consists of 50 samples from each of the three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepal and petals, in centimeters.\n",
    "\n",
    "![irisExplainedPic](https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/IrisDataSet.png)\n",
    "\n",
    "\n",
    "* The dataset contains a set of 150 records under five attributes - sepal length, sepal width, petal length, petal width and species.\n",
    "* The features are the measurements: sepal length, sepal width, petal length, petal width. \n",
    "* The labels will be the species which are mapped with numbers as: \n",
    "          0 := 'setosa' \n",
    "          1 := 'versicolor'\n",
    "          2 := 'virginica'\n",
    "          \n",
    "* Framed as a supervised learning problem: Predict the species (0: setosa, 1: versicolor, 2: virginica) of an iris using the measurements (sepal length, sepal width, petal legth, petal width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c866ca2",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae9fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X = irisDataFrame[iris.feature_names] # Features\n",
    "Y = irisDataFrame['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db99665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608527e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208899fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split( X, Y, train_size = 0.9, test_size = 0.1,\n",
    "                                                                     shuffle = True, random_state = 6174)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c83bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 4) (15, 4)\n",
      "(135,) (15,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes\n",
    "print ( X_train.shape, X_test.shape )\n",
    "print( Y_train.shape, Y_test.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756dc07",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 3: Logistic Regression\n",
    "![LogisticPic](https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/linear_vs_logistic_regression.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aac1693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "logistic_regression = linear_model.LogisticRegression().fit(X_train, Y_train) \n",
    "logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd29e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data point:\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "               5.1               3.5                1.4               0.2\n",
      "\n",
      "Probabilities for each possible class:\n",
      "╒═════════╤══════════════════════════╤═══════════════╕\n",
      "│ Class   │ Class name (iris type)   │   Probability │\n",
      "╞═════════╪══════════════════════════╪═══════════════╡\n",
      "│ 0       │ setosa                   │       0.98048 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 1       │ versicolor               │       0.01952 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 2       │ virginica                │       0       │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ Sum     │                          │       1       │\n",
      "╘═════════╧══════════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "sampleDataPoint = X[:1] # Pick a sample datapoint\n",
    "myPrediction = logistic_regression.predict_proba(sampleDataPoint)[0]  \n",
    "# Display to console\n",
    "print(\"Sample Data point:\")\n",
    "print( sampleDataPoint.to_string(index = False) )\n",
    "\n",
    "probData = [ ['0', 'setosa', \"{:0.5f}\".format(myPrediction[0]) ], \n",
    "             ['1', 'versicolor', \"{:0.5f}\".format(myPrediction[1]) ], \n",
    "             ['2', 'virginica', \"{:0.5f}\".format(myPrediction[2]) ],\n",
    "             ['Sum', '', myPrediction.sum()]\n",
    "           ]\n",
    "\n",
    "print( \"\\nProbabilities for each possible class:\")\n",
    "print(tabulate(probData, headers=[\"Class\",\"Class name (iris type)\", \"Probability\"], tablefmt='fancy_grid'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42398d9",
   "metadata": {},
   "source": [
    "**Now let's see how well the model (Logistic Regression) predicts on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e61c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "2          | 2          | 0.0001     | 0.1259        | 0.874     \n",
      "1          | 1          | 0.0026     | 0.8621        | 0.1352    \n",
      "2          | 2          | 0.0        | 0.0054        | 0.9946    \n",
      "1          | 1          | 0.0055     | 0.8173        | 0.1772    \n",
      "2          | 2          | 0.0001     | 0.0988        | 0.9012    \n",
      "1          | 1          | 0.0345     | 0.9494        | 0.0161    \n",
      "0          | 0          | 0.9701     | 0.0299        | 0.0       \n",
      "2          | 2          | 0.0        | 0.0068        | 0.9932    \n",
      "1          | 1          | 0.0655     | 0.9267        | 0.0078    \n",
      "0          | 0          | 0.9501     | 0.0499        | 0.0       \n",
      "0          | 0          | 0.975      | 0.025         | 0.0       \n",
      "1          | 1          | 0.0086     | 0.9349        | 0.0565    \n",
      "1          | 1          | 0.0198     | 0.9587        | 0.0215    \n",
      "1          | 1          | 0.0713     | 0.9245        | 0.0042    \n",
      "2          | 2          | 0.0        | 0.0199        | 0.9801    \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred_log_regression = logistic_regression.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs_y_log_regression = logistic_regression.predict_proba(X_test)\n",
    "\n",
    "probs_y_log_regression = np.round(probs_y_log_regression, 4)\n",
    "\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(Y_test, Y_pred_log_regression, \n",
    "                                                                                                             probs_y_log_regression[:,0],\n",
    "                                                                                                             probs_y_log_regression[:,1], \n",
    "                                                                                                             probs_y_log_regression[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807a672",
   "metadata": {},
   "source": [
    "**From the above table, we can see that we are correct in predicting the class all the time. Hence, the score on the test data will be 1. However, let's calculate it.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25da15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of model is:  0.9703703703703703\n",
      "The test score of model is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "\n",
    "train_score = logistic_regression.score( X_train, Y_train) # Calculate the score from the training data set\n",
    "test_score  = logistic_regression.score(X_test, Y_test)     # Calculate the score from the test data set\n",
    "\n",
    "# Display to console\n",
    "print(\"The training score of model is: \", train_score)\n",
    "print( \"The test score of model is: \", test_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb8a29",
   "metadata": {},
   "source": [
    "####  Report on the score for Logistic regression model, what does the score measure? \n",
    "* From the documentation, we know that the [score method](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) return the mean accuracy on the given test data and labels. Hence, the score measures the accuracy of the model on the given test data and labels.\n",
    "* The model got a perfect score of 1.0 on the test data. Meaning that the model accurately predicted the correct answer on the test data (as we saw previously in the above table).\n",
    "* The model got a score of 0.9703 on the training data. Meaning that the model accurately predicted the correct answer most of the time on the training data.\n",
    "* From the score, we can conclude that the model overall performed well on classifying iris class to which class belongs to based on the measurements (sepal's width, sepal's length, petal's width, petal's length). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50f64835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercepts:  9.61346, 2.10967, -11.72313\n",
      "\n",
      "Coefficients:  -0.39669, 0.90496, -2.43823, -1.08051, 0.49734, -0.28243, -0.19224, -0.88393, -0.10065, -0.62253, 2.63047, 1.96444\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "\n",
    "coefficients = logistic_regression.coef_      # extract coefficents \n",
    "intercepts = logistic_regression.intercept_   # extract intercepts\n",
    "\n",
    "# Display to console\n",
    "print(\"Intercepts:  \", end = '')\n",
    "for i in range( len(intercepts)):\n",
    "    if i != len(intercepts) -1:\n",
    "        print( \"{:0.5f}\".format(intercepts[i]), end = \", \" )\n",
    "    else:\n",
    "        print( \"{:0.5f}\".format(intercepts[i]), end = \"\\n\" )\n",
    "        \n",
    "print( \"\\nCoefficients:  \", end = '' )\n",
    "for i in range( len(coefficients)):\n",
    "    for j in  range( len(coefficients[i])):\n",
    "        if i == len(coefficients)-1 and j == len(coefficients[i])-1:\n",
    "            print( \"{:0.5f}\".format(coefficients[i][j]), end = \"\\n\")\n",
    "        else:\n",
    "            print( \"{:0.5f}\".format(coefficients[i][j]), end = \", \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e15a6",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 4: Support Vector Machine\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/SVC.jpg\" alt=\"Trulli\" style=\"width:40%\">\n",
    "\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4368161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "svmClassifier = svm.SVC( kernel = 'linear', probability = True)\n",
    "svmClassifier.fit( X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ddfe539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data point:\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "               6.3               3.3                6.0               2.5\n",
      "\n",
      "Probabilities for each possible class:\n",
      "╒═════════╤══════════════════════════╤═══════════════╕\n",
      "│ Class   │ Class name (iris type)   │   Probability │\n",
      "╞═════════╪══════════════════════════╪═══════════════╡\n",
      "│ 0       │ setosa                   │        0.0025 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 1       │ versicolor               │        0.0005 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 2       │ virginica                │        0.997  │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ Sum     │                          │        1      │\n",
      "╘═════════╧══════════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "sampleDataPoint = X[100:101] # Pick a sample datapoint\n",
    "myPrediction = svmClassifier.predict_proba(sampleDataPoint)[0]  \n",
    "# Display to console\n",
    "print(\"Sample Data point:\")\n",
    "print( sampleDataPoint.to_string(index = False) )\n",
    "\n",
    "probData = [ ['0', 'setosa', \"{:0.5f}\".format(myPrediction[0]) ], \n",
    "             ['1', 'versicolor', \"{:0.5f}\".format(myPrediction[1]) ], \n",
    "             ['2', 'virginica', \"{:0.5f}\".format(myPrediction[2]) ],\n",
    "             ['Sum', '', myPrediction.sum()]\n",
    "           ]\n",
    "\n",
    "print( \"\\nProbabilities for each possible class:\")\n",
    "print(tabulate(probData, headers=[\"Class\",\"Class name (iris type)\", \"Probability\"], tablefmt='fancy_grid'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aec1f5",
   "metadata": {},
   "source": [
    "**Now let's see how well the model (Support Vector Machine classification) predicts on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8909fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "2          | 2          | 0.0083     | 0.0721        | 0.9196    \n",
      "1          | 1          | 0.0033     | 0.9757        | 0.0209    \n",
      "2          | 2          | 0.0009     | 0.0004        | 0.9986    \n",
      "1          | 1          | 0.0065     | 0.9296        | 0.0639    \n",
      "2          | 2          | 0.0073     | 0.0586        | 0.9342    \n",
      "1          | 1          | 0.0238     | 0.9679        | 0.0083    \n",
      "0          | 0          | 0.9378     | 0.0464        | 0.0158    \n",
      "2          | 2          | 0.0024     | 0.002         | 0.9956    \n",
      "1          | 1          | 0.0427     | 0.9452        | 0.012     \n",
      "0          | 0          | 0.9187     | 0.0628        | 0.0184    \n",
      "0          | 0          | 0.9632     | 0.0264        | 0.0104    \n",
      "1          | 1          | 0.0074     | 0.9825        | 0.0101    \n",
      "1          | 1          | 0.0174     | 0.9763        | 0.0063    \n",
      "1          | 1          | 0.0577     | 0.9289        | 0.0135    \n",
      "2          | 2          | 0.0037     | 0.0031        | 0.9931    \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred_SVC = svmClassifier.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs_y_SVC = svmClassifier.predict_proba(X_test)\n",
    "\n",
    "probs_y_SVC = np.round(probs_y_SVC, 4)\n",
    "\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(Y_test, Y_pred_SVC, \n",
    "                                                                                                             probs_y_SVC[:,0],\n",
    "                                                                                                             probs_y_SVC[:,1], \n",
    "                                                                                                             probs_y_SVC[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d89af9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of model is:  0.9925925925925926\n",
      "The test score of model is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "\n",
    "train_score = svmClassifier.score( X_train, Y_train) # Calculate the score from the training data set\n",
    "test_score  = svmClassifier.score(X_test, Y_test)     # Calculate the score from the test data set\n",
    "\n",
    "# Display to console\n",
    "print(\"The training score of model is: \", train_score)\n",
    "print( \"The test score of model is: \", test_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb58f4",
   "metadata": {},
   "source": [
    "#### Report on the score for SVM, what does the score measure? \n",
    "* From the documentation, we know that the [score method](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) returns the mean accuracy on the given test data and labels. Hence, the score measure the accuracy of the model on the given test data and labels.\n",
    "* The model got a perfect score of 1.0 on the test data. Meaning that the model accurately predicted the correct answer on the test data (as we saw previously in the above table). Comparing it with the Logistic Regression, SVM had a greater probability in predicting the correct class (it was more certain about the correct answer).\n",
    "* The model got a score of 0.99259 on the training data. Meaning that the model accurately predicted the correct answer most of the time on the training data (it failed on one).\n",
    "* From the score, we can conclude that the model overall performed well on classifying iris class to which class belongs to based on the measuremenrs (sepal's width, sepal's length, petal's width, petal's length).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b28f6d8",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 5: Neural Network \n",
    "\n",
    "\n",
    "<figure>\n",
    "<img src = \"https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/multilayerperceptron_network.png\" alt=\"Trulli\" style=\"width:40%\">\n",
    "</figure>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68ed09fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(150,), max_iter=500,\n",
       "              random_state=1, solver='lbfgs')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "\n",
    "neuralNetworkModel = neural_network.MLPClassifier(random_state = 1, hidden_layer_sizes = (150,), solver = 'lbfgs',\n",
    "                                                  max_iter = 500, activation = 'logistic' ).fit(X_train, Y_train)\n",
    "\n",
    "neuralNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5b7c938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data point:\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "               6.3               3.3                6.0               2.5\n",
      "\n",
      "Probabilities for each possible class:\n",
      "╒═════════╤══════════════════════════╤═══════════════╕\n",
      "│ Class   │ Class name (iris type)   │   Probability │\n",
      "╞═════════╪══════════════════════════╪═══════════════╡\n",
      "│ 0       │ setosa                   │             0 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 1       │ versicolor               │             0 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 2       │ virginica                │             1 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ Sum     │                          │             1 │\n",
      "╘═════════╧══════════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "sampleDataPoint = X[100:101] # Pick a sample datapoint\n",
    "\n",
    "myPrediction = neuralNetworkModel.predict_proba(sampleDataPoint)[0]  \n",
    "\n",
    "# Display to console\n",
    "print(\"Sample Data point:\")\n",
    "print( sampleDataPoint.to_string(index = False) )\n",
    "\n",
    "probData = [ ['0', 'setosa', \"{:0.5f}\".format(myPrediction[0]) ], \n",
    "             ['1', 'versicolor', \"{:0.5f}\".format(myPrediction[1]) ], \n",
    "             ['2', 'virginica', \"{:0.5f}\".format(myPrediction[2]) ],\n",
    "             ['Sum', '', myPrediction.sum()]\n",
    "           ]\n",
    "\n",
    "print( \"\\nProbabilities for each possible class:\")\n",
    "print(tabulate(probData, headers=[\"Class\",\"Class name (iris type)\", \"Probability\"], tablefmt='fancy_grid'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12cef8",
   "metadata": {},
   "source": [
    "**Now let's see how well the model (Multi-layer Perceptron classifier with the folowing hyperparameters: hidden_layer_size = (150,), solver = 'lbfgs', max_iter = 500, activation = 'logistic') predicts on the test data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc2cc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "0          | 0          | 1.0        | 0.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "0          | 0          | 0.9999     | 0.0001        | 0.0       \n",
      "0          | 0          | 1.0        | 0.0           | 0.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "1          | 1          | 0.0002     | 0.9998        | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred_MLP = neuralNetworkModel.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs_y_MLP = neuralNetworkModel.predict_proba(X_test)\n",
    "\n",
    "probs_y_MLP = np.round(probs_y_MLP, 4)\n",
    "\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(Y_test, Y_pred_MLP, \n",
    "                                                                                                             probs_y_MLP[:,0],\n",
    "                                                                                                             probs_y_MLP[:,1], \n",
    "                                                                                                             probs_y_MLP[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c68c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of model is:  1.0\n",
      "The test score of model is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "\n",
    "train_score = neuralNetworkModel.score( X_train, Y_train) # Calculate the score from the training data set\n",
    "test_score  = neuralNetworkModel.score(X_test, Y_test)     # Calculate the score from the test data set\n",
    "\n",
    "# Display to console\n",
    "print(\"The training score of model is: \", train_score)\n",
    "print( \"The test score of model is: \", test_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a67e38",
   "metadata": {},
   "source": [
    "#### Report on the score for MLPClassifier, what does the score measure? \n",
    "* From the documentation, we know that the [score method](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) returns the mean accuracy on the given test data and labels. Hence, the score measure the accuracy of the model on the given test data and labels.\n",
    "* The model got a perfect score of 1.0 on the test data. Meaning that the model accurately predicted the correct answer on the test data (as we saw previously in the above table). Comparing it with the Logistic Regression and SVM, the MLPClassifier had a greater probability (very close to 1.0) in predicting the correct class (the model was near 100% certain about the correct answer). \n",
    "* The model got a score of 1.0 on the training data. Meaning that the model accurately predicted the correct answer on all the training data. \n",
    "* From the score, we can conclude that the model overall performed perfectly on classifying iris class to which class belongs to based on the measuremenrs (sepal's width, sepal's length, petal's width, petal's length)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94c19f",
   "metadata": {},
   "source": [
    "#### iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "\n",
    "* The highest score gotten was 1.0 on both training and testing data. \n",
    "* The model configuration was as follow:\n",
    "    * hidden_layer_size = (150,)\n",
    "    * solver = 'lbfgs'\n",
    "    * max_iter = 500\n",
    "    * activation = 'logistic'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2ba42",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 6: K-Nearest Neighbors\n",
    "\n",
    "![K-NNImage](https://raw.githubusercontent.com/billydavila/CSC448/main/Judging%20Flowers/K-NN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7911ad77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "KNN_model = neighbors.KNeighborsClassifier( n_neighbors = 1)\n",
    "\n",
    "# TODO: Do we 'train' the model as a whole without the training data? model.fit(X,Y)\n",
    "KNN_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3e8e01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data point:\n",
      " sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "               6.3               3.3                6.0               2.5\n",
      "\n",
      "Probabilities for each possible class:\n",
      "╒═════════╤══════════════════════════╤═══════════════╕\n",
      "│ Class   │ Class name (iris type)   │   Probability │\n",
      "╞═════════╪══════════════════════════╪═══════════════╡\n",
      "│ 0       │ setosa                   │             0 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 1       │ versicolor               │             0 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ 2       │ virginica                │             1 │\n",
      "├─────────┼──────────────────────────┼───────────────┤\n",
      "│ Sum     │                          │             1 │\n",
      "╘═════════╧══════════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "\n",
    "sampleDataPoint = X[100:101] # Pick a sample datapoint\n",
    "\n",
    "myPrediction = KNN_model.predict_proba(sampleDataPoint)[0]  \n",
    "\n",
    "# Display to console\n",
    "print(\"Sample Data point:\")\n",
    "print( sampleDataPoint.to_string(index = False) )\n",
    "\n",
    "probData = [ ['0', 'setosa', \"{:0.5f}\".format(myPrediction[0]) ], \n",
    "             ['1', 'versicolor', \"{:0.5f}\".format(myPrediction[1]) ], \n",
    "             ['2', 'virginica', \"{:0.5f}\".format(myPrediction[2]) ],\n",
    "             ['Sum', '', myPrediction.sum()]\n",
    "           ]\n",
    "\n",
    "print( \"\\nProbabilities for each possible class:\")\n",
    "print(tabulate(probData, headers=[\"Class\",\"Class name (iris type)\", \"Probability\"], tablefmt='fancy_grid'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6970d41",
   "metadata": {},
   "source": [
    "**Now let's see how well the model (K-nearest neighbors classifier) predicts on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea708475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test     | y_pred     | Setosa(%)  | versicolor(%) | virginica(%)\n",
      "-----------------------------------------------------------------\n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "0          | 0          | 1.0        | 0.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "0          | 0          | 1.0        | 0.0           | 0.0       \n",
      "0          | 0          | 1.0        | 0.0           | 0.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "1          | 1          | 0.0        | 1.0           | 0.0       \n",
      "2          | 2          | 0.0        | 0.0           | 1.0       \n",
      "-----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "Y_pred_KNN = KNN_model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs_y_KNN = KNN_model.predict_proba(X_test)\n",
    "\n",
    "probs_y_KNN = np.round(probs_y_KNN, 4)\n",
    "\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(Y_test, Y_pred_KNN, \n",
    "                                                                                                             probs_y_KNN[:,0],\n",
    "                                                                                                             probs_y_KNN[:,1], \n",
    "                                                                                                             probs_y_KNN[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a34a759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score of model is:  1.0\n",
      "The test score of model is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "\n",
    "train_score = KNN_model.score( X_train, Y_train) # Calculate the score from the training data set\n",
    "test_score  = KNN_model.score(X_test, Y_test)     # Calculate the score from the test data set\n",
    "\n",
    "# Display to console\n",
    "print(\"The training score of model is: \", train_score)\n",
    "print( \"The test score of model is: \", test_score )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce137b67",
   "metadata": {},
   "source": [
    "#### Report on the score for KNeighborsClassifier, what does the score measure? \n",
    "* From the documentation, we know that the [score method](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) returns the mean accuracy on the given test data and labels. Hence, the score measure the accuracy of the model on the given test data and labels.\n",
    "* The model got a perfect score of 1.0 on the test data. Meaning that the model accurately predicted the correct answer on the test data (as we saw previously in the above table). Comparing it with Logistic Regression, SVM, and the MLPClassifier, the KNN-Classifier had a greater probability (1.0) in predicting the correct class (the model was 100% certain about the correct answer). \n",
    "* The model got a score of 1.0 on the training data. Meaning that the model accurately predicted the correct answer on all the training data. \n",
    "* From the score, we can conclude that the model overall performed perfectly on classifying iris class to which class belongs to based on the measuremenrs (sepal's width, sepal's length, petal's width, petal's length)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91f807",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "**In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?**\n",
    "\n",
    "### Summary of the models' results:\n",
    "\n",
    "| Model                          |  Configuration                                  | Training Score | Test score |\n",
    "| :-----------------------------:| :----------------------------------------------:| :-------------:| :---------:|\n",
    "| Logistic Regression            |     default                                     |    0.97037     |   1.0      |\n",
    "| SVM ( SVM)                     | kernel = 'linear', probability = True           |    0.9925      |   1.0      |\n",
    "| Neural Network (MLPClassifier)       | hidden_layer_sizes = (150,), solver = 'lbfgs', max_iter = 500, activation = 'logistic' |     1.0        |   1.0      |  \n",
    "| K-nearest Neighbors            | n_neighbors = 1                                 |     1.0        |    1.0     |\n",
    "\n",
    "\n",
    "\n",
    "* Looking at the models' scores, all the models performed overall well on classifying iris class to their corresponding class based on the measurements (sepal's width, sepal's length, petal's width, petal's length). \n",
    "\n",
    "####  Which model(s) performed the best on the dataset?\n",
    "* The two models that performed the best on the dataset were the **Neural Network Classifier** and **K-nearest Neighbors** with a perfect score on 1.0 (for both training and test dataset). However, in predicting the probability the **K-nearest Neighbors** model was 100% certain about the correct answer on the test data set. Another important point to mention is that unlike neural network, KNN classifier does not have an expensive training phase. \n",
    "\n",
    "#### why do you think that is? \n",
    "* I believe this is because KNN is an example of a nonparametric model. In nonparametric models, the number of parameters are theoritically infinite (parameters grow as data grows). \n",
    "* Neural networks are somewhat related to logistic regression. Basically, we can think of logistic regression as a one layer neural network. Hence, if we add more hidden layers, we can improve on the performance of the model (which was the case in this exercise). \n",
    "* In summary, I would first approach a classification problem with simple models first (e.g. logistic regression). However, if we are not satisfied with its performance, we can try to train a computationally more expensive neural networl, which has the advantage to learn more complex, non-linear functions.\n",
    "\n",
    "#### Did anything surprise you about the exercise? \n",
    "* The score accuracy of all the model on the testing data. They were all perfect.\n",
    "* When I was testing different configurations for KNN-model, the best one was having only one neighbors while adding more neighbors will give me worse performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec7986b",
   "metadata": {},
   "source": [
    "***\n",
    "# References\n",
    "1. [Scikit learn: Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "2. [Scikit learn: svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "3. [Scikit learn: Neural Network models](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)\n",
    "4. [Scikit learn: MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n",
    "5. [Scikit learn: KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3457788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
